{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kunalkhatri/Desktop/Semester1/CV/Project\n",
      "768\n",
      "[5, 5, 2, 8, 11, 8, 17, 22, 18, 25, 37, 34, 46, 47, 63, 66, 75, 105, 121, 111, 144, 167, 160, 214, 183, 215, 186, 206, 204, 187, 202, 201, 191, 183, 207, 201, 204, 222, 222, 223, 260, 245, 249, 292, 305, 320, 343, 357, 373, 434, 484, 528, 592, 659, 763, 807, 880, 946, 955, 980, 995, 1033, 1166, 1211, 1336, 1327, 1416, 1440, 1522, 1536, 1632, 1624, 1668, 1673, 1727, 1766, 1913, 1850, 1980, 1881, 2015, 1879, 1976, 1927, 2007, 2047, 2072, 2067, 2024, 2048, 2163, 2140, 2237, 2253, 2312, 2296, 2388, 2434, 2310, 2374, 2373, 2338, 2303, 2186, 2125, 2016, 1968, 1829, 1780, 1567, 1589, 1404, 1243, 1196, 1189, 1060, 1100, 1040, 954, 942, 862, 878, 810, 814, 724, 793, 704, 719, 668, 608, 605, 550, 593, 574, 534, 464, 482, 463, 453, 446, 430, 432, 412, 390, 383, 355, 351, 356, 358, 359, 373, 352, 305, 305, 302, 243, 281, 281, 272, 282, 275, 235, 261, 254, 261, 238, 249, 235, 246, 227, 231, 269, 238, 229, 249, 261, 240, 230, 244, 221, 218, 199, 184, 178, 159, 150, 134, 166, 147, 128, 127, 103, 107, 119, 112, 122, 101, 107, 105, 132, 105, 106, 103, 106, 96, 89, 110, 103, 107, 117, 124, 111, 97, 108, 84, 60, 67, 95, 82, 62, 65, 86, 90, 136, 88, 100, 26, 33, 82, 53, 27, 24, 38, 58, 52, 41, 18, 33, 51, 33, 54, 16, 31, 50, 39, 48, 66, 22, 32, 60, 83, 47, 92, 159, 240, 751, 1, 2, 2, 0, 4, 1, 7, 3, 10, 9, 9, 11, 10, 2, 18, 23, 31, 26, 28, 25, 25, 37, 35, 43, 56, 64, 72, 85, 94, 103, 116, 156, 148, 173, 173, 175, 198, 217, 182, 217, 196, 238, 216, 221, 198, 195, 209, 188, 203, 198, 235, 234, 227, 226, 220, 229, 219, 243, 241, 232, 263, 231, 222, 225, 213, 223, 244, 261, 253, 265, 250, 320, 332, 316, 370, 362, 390, 440, 434, 416, 441, 463, 518, 573, 535, 603, 671, 698, 739, 798, 873, 922, 935, 882, 816, 863, 770, 788, 832, 746, 704, 721, 807, 826, 899, 960, 954, 1043, 1101, 1118, 1228, 1232, 1325, 1434, 1494, 1597, 1633, 1626, 1656, 1715, 1663, 1722, 1817, 1883, 1769, 1838, 1777, 1780, 1872, 1922, 1941, 1894, 1839, 1886, 1924, 2013, 1973, 2000, 2035, 2029, 2141, 2160, 2113, 2066, 2041, 2050, 1979, 1962, 1914, 1965, 1821, 1788, 1566, 1510, 1357, 1308, 1222, 1065, 957, 940, 890, 862, 862, 768, 758, 732, 718, 643, 639, 613, 568, 594, 536, 551, 510, 509, 517, 477, 484, 441, 463, 417, 386, 431, 384, 403, 348, 385, 367, 354, 359, 310, 278, 295, 278, 258, 252, 233, 242, 222, 222, 230, 240, 220, 226, 203, 212, 192, 187, 243, 240, 263, 217, 235, 187, 180, 204, 199, 195, 180, 153, 167, 149, 160, 135, 129, 121, 124, 112, 112, 120, 131, 121, 123, 91, 124, 130, 117, 86, 107, 124, 87, 104, 105, 122, 118, 134, 127, 136, 123, 116, 184, 284, 609, 798, 1175, 53, 31, 26, 51, 67, 123, 133, 225, 345, 427, 576, 706, 896, 1094, 1117, 1345, 1417, 1426, 1254, 1224, 1229, 1182, 1186, 1215, 1159, 1168, 1103, 1204, 1255, 1264, 1346, 1329, 1276, 1429, 1443, 1406, 1411, 1402, 1374, 1356, 1390, 1464, 1512, 1527, 1583, 1615, 1592, 1629, 1575, 1665, 1643, 1676, 1575, 1646, 1636, 1658, 1642, 1661, 1728, 1718, 1561, 1550, 1685, 1595, 1542, 1544, 1506, 1520, 1453, 1366, 1410, 1256, 1391, 1274, 1182, 1232, 1178, 1170, 1058, 1134, 1019, 1062, 985, 884, 873, 845, 765, 797, 760, 730, 761, 718, 728, 665, 731, 675, 612, 623, 669, 633, 567, 539, 595, 597, 533, 533, 533, 488, 473, 524, 446, 440, 421, 485, 437, 421, 430, 387, 396, 371, 353, 355, 328, 330, 316, 341, 334, 318, 310, 288, 290, 294, 294, 222, 264, 259, 302, 259, 280, 235, 218, 254, 240, 256, 231, 238, 202, 202, 229, 221, 194, 218, 212, 193, 225, 218, 228, 200, 184, 236, 204, 199, 172, 188, 205, 181, 186, 176, 191, 203, 190, 177, 185, 205, 177, 189, 174, 189, 195, 170, 191, 198, 168, 162, 175, 167, 177, 141, 185, 159, 174, 161, 160, 184, 175, 191, 180, 180, 160, 160, 146, 163, 153, 152, 171, 140, 151, 136, 160, 150, 166, 138, 154, 160, 142, 139, 138, 133, 153, 126, 132, 159, 128, 147, 138, 146, 126, 136, 130, 145, 160, 141, 142, 174, 180, 153, 163, 172, 168, 169, 160, 145, 154, 137, 164, 145, 140, 145, 196, 229, 392, 709, 850, 936, 825, 1452]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "print (os.getcwd())\n",
    "\n",
    "image = Image.open(\"../Project/img1.jpg\")\n",
    "histogram = image.histogram()\n",
    "print(len(histogram))\n",
    "print(histogram)\n",
    "type(histogram)\n",
    "#plt.figure(histogram)\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_file_paths_n_labels():\n",
    "    \"\"\"\n",
    "    Get array train_file_paths, train_labels, test_file_paths and test_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Data loading and data generators set up\n",
    "    par_data_dir = 'CUB_200_2011/CUB_200_2011'\n",
    "    images_data_dir = 'CUB_200_2011/CUB_200_2011/images'\n",
    "    train_test_split_file = os.path.join(par_data_dir, 'train_test_split.txt')\n",
    "    images_file = os.path.join(par_data_dir, 'images.txt')\n",
    "    labels_file = os.path.join(par_data_dir, 'image_class_labels.txt')\n",
    "\n",
    "    # Read the images_file which stores image-id and image-name mapping\n",
    "    image_file_id_df = pd.read_csv(images_file, sep=' ', header=None)\n",
    "    image_file_id_mat = image_file_id_df.as_matrix()\n",
    "    image_id_name_map = dict(zip(image_file_id_mat[:, 0], image_file_id_mat[:, 1]))\n",
    "\n",
    "    # Read the train_test_split file which stores image-id and train-test split mapping\n",
    "    image_id_train_test_split_df = pd.read_csv(train_test_split_file, sep=' ', header=None)\n",
    "    image_id_train_test_split_mat = image_id_train_test_split_df.as_matrix()\n",
    "    image_id_train_test_split_map = dict(zip(image_id_train_test_split_mat[:, 0],\n",
    "                                             image_id_train_test_split_mat[:, 1]))\n",
    "\n",
    "    # Read the image class labels file\n",
    "    image_id_label_df = pd.read_csv(labels_file, sep=' ', header=None)\n",
    "    image_id_label_mat = image_id_label_df.as_matrix()\n",
    "    image_id_label_map = dict(zip(image_id_label_mat[:, 0], image_id_label_mat[:, 1]))\n",
    "\n",
    "    # Put together train_files train_labels test_files and test_labels lists\n",
    "    train_image_ids, test_image_ids = [], []\n",
    "    train_file_paths, test_file_paths = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "    for file_id in image_id_name_map.keys():\n",
    "        file_name = image_id_name_map[file_id]\n",
    "        is_train = image_id_train_test_split_map[file_id]\n",
    "        label = image_id_label_map[file_id] - 1  # To ensure labels start from 0\n",
    "\n",
    "        if is_train:\n",
    "            train_image_ids.append(file_id)\n",
    "            train_file_paths.append(os.path.join(images_data_dir, file_name))\n",
    "            train_labels.append(label)\n",
    "        else:\n",
    "            test_image_ids.append(file_id)\n",
    "            test_file_paths.append(os.path.join(images_data_dir, file_name))\n",
    "            test_labels.append(label)\n",
    "\n",
    "    print (\"Length of train files list\", len(train_file_paths))\n",
    "    print (\"Length of train labels list\", len(train_labels))\n",
    "    print (\"Length of test files list\", len(test_file_paths))\n",
    "    print (\"Length of test labels list\", len(test_labels))\n",
    "\n",
    "    return train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train files list 5994\n",
      "Length of train labels list 5994\n",
      "Length of test files list 5794\n",
      "Length of test labels list 5794\n"
     ]
    }
   ],
   "source": [
    "train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels = get_train_test_file_paths_n_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "Length of X_train 5990\n",
      "Legth of y_train 5990\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i, y in zip(train_file_paths, train_labels):\n",
    "    image = Image.open(i)\n",
    "    histogram = image.histogram()\n",
    "    if len(histogram) != 768:\n",
    "        print(\"error\")\n",
    "        continue\n",
    "    X_train.append(histogram)\n",
    "    y_train.append(y)\n",
    "print (\"Length of X_train\", len(X_train))\n",
    "print (\"Legth of y_train\", len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5990 5990\n"
     ]
    }
   ],
   "source": [
    "print (len(X_train), len(y_train))\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=True, random_state=42,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define support vector classifier\n",
    "svm = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# fit model\n",
    "svm.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "5790\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for i, y in zip(test_file_paths, test_labels):\n",
    "    image = Image.open(i)\n",
    "    histogram = image.histogram()\n",
    "    if len(histogram) != 768:\n",
    "        print(\"error\")\n",
    "        continue\n",
    "    X_test.append(histogram)\n",
    "    y_test.append(y)\n",
    "\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5790 5790\n"
     ]
    }
   ],
   "source": [
    "print (len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02243700379703141"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                             random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113, 193, 55, 148, 84, 120, 168, 194, 131, 130, 129, 58, 51, 32, 79, 131, 68, 3, 102, 115]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (y_train[:20])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0051813471502590676"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
